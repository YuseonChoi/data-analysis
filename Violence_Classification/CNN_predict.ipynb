{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 39, 1291, 16)      80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 19, 645, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 19, 645, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 18, 644, 32)       2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 9, 322, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 9, 322, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 321, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 160, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 160, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 159, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 79, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 79, 128)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 22)                2838      \n",
      "=================================================================\n",
      "Total params: 46,150\n",
      "Trainable params: 46,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"CNN_all_model_final.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    mfccs = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mAnnotatedAudioFiles\u001b[0m/\r\n",
      "\u001b[01;34mAnnotatedAudioFiles_tmp\u001b[0m/\r\n",
      "\u001b[01;34mCNN_all\u001b[0m/\r\n",
      "CNN_all_classification_model.ipynb\r\n",
      "CNN_all_model.h5\r\n",
      "CNN_all_preprocessing.ipynb\r\n",
      "CNN_code_classification_model.ipynb\r\n",
      "CNN_event_classification_model.ipynb\r\n",
      "CNN_event_preprocessing.ipynb\r\n",
      "CNN_model.h5\r\n",
      "CNN_predict.ipynb\r\n",
      "\u001b[01;34mCNN_predict_data\u001b[0m/\r\n",
      "CNN_situation_classification_model.ipynb\r\n",
      "CNN_situation_preprocessing.ipynb\r\n",
      "KNN_binary_classification.ipynb\r\n",
      "KNN_code_classification.ipynb\r\n",
      "KNN_event_classification.ipynb\r\n",
      "KNN_predict.ipynb\r\n",
      "KNN_situation_classification.ipynb\r\n",
      "Untitled-Copy1.ipynb\r\n",
      "Untitled.ipynb\r\n",
      "Untitled1.ipynb\r\n",
      "Untitled2.ipynb\r\n",
      "Untitled3.ipynb\r\n",
      "binary_classification.ipynb\r\n",
      "convert_mp3_to_wav.ipynb\r\n",
      "\u001b[01;34mconvert_wav\u001b[0m/\r\n",
      "convert_wav.ipynb\r\n",
      "convert_wav_final.ipynb\r\n",
      "crop_event.ipynb\r\n",
      "crop_wav.ipynb\r\n",
      "cut_file.wav\r\n",
      "\u001b[01;34mdata\u001b[0m/\r\n",
      "data_preprocessing.ipynb\r\n",
      "dataframe_add_file_name.ipynb\r\n",
      "event_data_preprocesssing.csv\r\n",
      "event_data_preprocesssing_final.csv\r\n",
      "event_data_preprocesssing_jjin_real_final.csv\r\n",
      "event_data_preprocesssing_real_final.csv\r\n",
      "\u001b[01;34mffmpeg-4.4.1-amd64-static\u001b[0m/\r\n",
      "knn_binary_model.pkl\r\n",
      "knn_code_model.pkl\r\n",
      "knn_model.pkl\r\n",
      "knn_situation_model.pkl\r\n",
      "model_classification2.ipynb\r\n",
      "raw_data.ipynb\r\n",
      "same_crop_wav.ipynb\r\n",
      "\u001b[01;34msame_sound_extract\u001b[0m/\r\n",
      "\u001b[01;34msound_extract\u001b[0m/\r\n",
      "star_pydub.ipynb\r\n",
      "test.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.2899487e+02, -5.2899487e+02, -5.2564697e+02, ...,\n",
       "        -2.1546034e+02, -2.3469844e+02, -2.4204639e+02],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  4.6393204e+00, ...,\n",
       "         1.3780266e+02,  1.2830196e+02,  1.3664249e+02],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  4.3624334e+00, ...,\n",
       "        -1.2969001e+01, -4.4036245e+00, -7.2050619e+00],\n",
       "       ...,\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  3.2161161e-01, ...,\n",
       "         5.1554346e+00,  9.1413536e+00,  2.7488253e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  4.3222263e-01, ...,\n",
       "        -3.5348375e+00, -6.5571308e+00, -2.0395958e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  4.6939585e-01, ...,\n",
       "        -8.3651543e+00, -1.4543214e+01, -1.1859083e+01]], dtype=float32)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = extract_feature(\"CNN_predict_data/crop_data/음성 012.wav\")\n",
    "x = np.array(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 1292)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40, 1292, 1)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape(-1, x.shape[0], x.shape[1], 1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.7405980e-01, 3.2373759e-08, 5.6599561e-02, 2.3001599e-10,\n",
       "        2.4285325e-04, 1.6147196e-01, 4.0436906e-01, 7.9433211e-18,\n",
       "        1.6372377e-07, 3.9972807e-09, 9.0428914e-12, 2.5526543e-07,\n",
       "        2.8959978e-03, 3.6025449e-04, 5.3312663e-18]], dtype=float32)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각각 22개의 상황 라벨에 대한 확률값\n",
    "y = model.predict(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.argmax(y)\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_code = {'dating-violence': 0, 'injury': 1, 'office-violence': 2, 'rape':3, 'robber': 4, 'sponsor': 5, 'violence': 6, \n",
    "              'candid-cam': 7, 'disorder': 8, 'drunken': 9, 'flasher': 10, 'inebriate': 11, 'invasion': 12, 'crying': 13, 'normal': 14}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {v:k for k,v in class_code.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'violence'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
